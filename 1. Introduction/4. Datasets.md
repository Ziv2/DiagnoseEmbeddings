# Datasets to Evaluate Textual Embeddings

## Datasets for Word Embeddings Quality Evaluation
| Name of Dataset | Link to the Dataset | License | Relevant Models | How to Use | Ease of Implementation | Importance |
|------------------|---------------------|---------|------------------|------------|-------------------------|------------|
| WordSim-353 | [WordSim-353](https://aclweb.org/aclwiki/WordSimilarity-353_Test_Collection_(State_of_the_art)) | Free for academic use | Word2Vec, GloVe, FastText | Compute similarity scores for word pairs and compare with human scores. | Easy | High - widely used for word similarity benchmarks. |
| MEN Dataset | [MEN Dataset](https://staff.fnwi.uva.nl/e.bruni/MEN) | Free for research purposes | Word2Vec, GloVe | Evaluate word similarity using paired comparisons with human annotations. | Easy | High - comprehensive annotations for similarity testing. |
| SimLex-999 | [SimLex-999](https://fh295.github.io/simlex.html) | CC BY-SA 4.0 | Word2Vec, FastText, BERT | Measure semantic similarity across diverse word pairs. | Moderate | High - focuses on true semantic similarity rather than association. |
| CARD-660 Rare Words (RW) Dataset | [RW Dataset](https://paperswithcode.com/dataset/card-660) | Free for research purposes | Word2Vec, GloVe | Evaluate embedding performance on less frequent words. | Moderate | Medium - highlights model performance on low-frequency vocabulary. |
| Google Analogy Test Set | [Google Analogy Test Set](https://code.google.com/archive/p/word2vec/) | Free for academic use | Word2Vec, GloVe | Assess syntactic and semantic analogy tasks. | Moderate | High - common benchmark for analogy tasks. |



## Datasets for Sentence Embeddings Quality Evaluation

| Name of Dataset | Link to the Dataset | License | Relevant Models | How to Use | Ease of Implementation | Importance |
|------------------|---------------------|---------|------------------|------------|-------------------------|------------|
| STS Benchmark | [STS Benchmark](https://paperswithcode.com/dataset/sts-benchmark) | Free for research purposes | SBERT, USE, InferSent | Evaluate semantic textual similarity with human-annotated sentence pairs. | Easy | High - gold standard for sentence similarity evaluation. |
| SICK Dataset | [SICK Dataset](https://paperswithcode.com/dataset/sick) | Creative Commons Attribution | SBERT, InferSent | Test sentence similarity and entailment capabilities of embeddings. | Moderate | High - evaluates both similarity and entailment relationships. |
| Quora Question Pairs | [Quora Question Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs) | Quora-specific license | USE, SBERT | Measure embedding performance on duplicate question detection. | Moderate | High - real-world relevance for question-matching tasks. |
| STS12-16 (Semantic Textual Similarity) | [STS12-16](http://ixa2.si.ehu.eus/stswiki/) | Free for research purposes | SBERT, USE | Assess semantic similarity with diverse sentence pairs from multiple datasets. | Easy | High - benchmark for cross-year sentence similarity evaluation. |
| Multi-Genre NLI (MNLI) Corpus | [MNLI](https://cims.nyu.edu/~sbowman/multinli/) | Free for research purposes | BERT, RoBERTa, DeBERTa | Evaluate entailment and contradiction in sentence embeddings. | Moderate | High - provides multi-domain entailment testing. |


## Datasets for Paragraph Embeddings Quality Evaluation

| Name of Dataset | Link to the Dataset | License | Relevant Models | How to Use | Ease of Implementation | Importance |
|------------------|---------------------|---------|------------------|------------|-------------------------|------------|
| Wikipedia Dumps | [Wikipedia Dumps](https://dumps.wikimedia.org/) | CC BY-SA 3.0 | Doc2Vec, Longformer, BERT | Train or evaluate embeddings on diverse textual data. | Moderate | High - diverse and large-scale dataset for robust training and testing. |
| BookCorpus | [BookCorpus](https://yknzhu.wixsite.com/mbweb) | Free for academic use | GPT, BERT, RoBERTa | Pretrain or test models with long textual data. | Moderate | High - large corpus for pretraining language models. |
| arXiv Dataset | [arXiv Dataset](https://www.kaggle.com/Cornell-University/arxiv) | Free for research purposes | SciBERT, Longformer | Evaluate paragraph-level embeddings in scientific contexts. | Moderate | High - domain-specific for scientific text analysis. |
| Amazon Review Corpus | [Amazon Review Corpus](https://nijianmo.github.io/amazon/index.html) | CC BY-NC-SA 4.0 | Doc2Vec, GPT | Test embeddings on sentiment and product categorization tasks. | Moderate | Medium - real-world dataset for sentiment analysis. |
| Yelp Reviews Dataset | [Yelp Dataset](https://www.yelp.com/dataset) | Yelp license | Doc2Vec, GPT | Evaluate paragraph-level sentiment and text classification. | Easy | Medium - real-world application for review analysis. |
